name: local_llm_promptflow
channels:
  - defaults
  - conda-forge
dependencies:
  - python=3.11.8
  - pip
  - pip:
      - fastapi[all]==0.110.0
      # - llama-cpp-python==0.2.56  # for CPU only
      - llama-cpp-python==0.2.56 -C cmake.args="-DLLAMA_METAL=on"  # for running on Mac GPU
      - pre-commit
      - promptflow==1.6.0
      - promptflow-tools==1.3.0
      - pyyaml
      - requests
